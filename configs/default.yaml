project_name: "geoscreens"
seed: 42
gpus: [1]

env:
  # Similar to cache dir, but can be used if specifically want to override where MMF stores your
  # data. Default would be cache_dir/data. We will auto download models and datasets in this folder
  data_dir: ${resolve_dir:ICEDET_DATA_DIR, datasets}

  # Directory for saving checkpoints and other metadata Use ICEDET_SAVE_DIR or env.save_dir to
  # override. This will get the experiment_name appended as a subdirectory automatically.
  save_dir: ${env:ICEDET_SAVE_DIR, ./output}

  # Log directory for Weights and Biases, default points to same as logs Only used when
  # training.wandb is enabled. Use ICEDET_WANDB_LOGDIR or env.wandb_logdir to override
  wandb_logdir: ${env:ICEDET_WANDB_LOGDIR,}

model_config:
  # Options: torchvision, mmdet, ross, ultralytics
  framework: "torchvision"
  name: "retinanet"
  # backbone: "resnet_50_fpn"
  params:
    detections_per_img: 512
    # Anchor box sizes. Default:  [32, 64, 128, 256, 512]
    anchor_sizes: [32, 64, 128, 256, 512]
    # Anchor box aspect ratios (h/w). Default: [0.5, 1.0, 2.0]
    aspect_ratios: [0.08, 0.16, 0.25, 0.36, 0.5, 0.7, 1.0, 2.0]
    score_thresh: 0.05
    nms_thresh: 0.5
    fg_iou_thresh: 0.5
    bg_iou_thresh: 0.4

dataset_config:
  dataset_name: geoscreens_001
  # If a relative path, it's relative to PROJECT_ROOT (aka root of the git repo if you've cloned
  # this project);
  data_root: "./datasets"
  # If a relative path, it's relative to PROJECT_ROOT (aka root of the git repo if you've cloned
  # this project);
  img_dir: "./datasets/images"
  img_size: 640
  # Include an extra class in num_classes for the background class (which gets added automatically)
  num_classes: 47
  batch_size: ${training.batch_size}
  num_workers: ${training.num_workers}
  pin_memory: ${training.pin_memory}

training:
  # Name of the experiment, will be used while saving checkpoints and generating reports
  experiment_name: run
  # Size of the batch globally. If distributed or data_parallel is used, this will be divided
  # equally among GPUs
  batch_size: 12
  # Number of workers to be used in dataloaders
  num_workers: 4
  # Whether to pin memory in dataloader
  pin_memory: false
  # After `checkpoint_interval` number of updates, MMF will make a snapshot which will involve
  # creating a checkpoint for current training scenarios
  checkpoint_interval: 1000
  # This will evaluate evaluation metrics on whole validation set after evaluation interval number
  # of updates
  evaluation_interval: 1000

  # These are passed to the constructor for the Lightning Trainer
  params:
    max_epochs: 80
    gpus: [1]
    precision: 16
    amp_backend: "native"
    check_val_every_n_epoch: 5
    # Enable anomaly detection for the autograd engine. i.e., terminate on NaN/Inf loss.
    detect_anomaly: true
    # If ``True``, sets whether PyTorch operations must use deterministic algorithms. Default:
    # ``False``.
    deterministic: False
    # Enables cudnn.benchmark
    benchmark: True

  early_stop:
    # Whether to use early stopping, (Default: false)
    enabled: false
    params:
      # Patience for early stoppings
      patience: 4
      # Criteria to be monitored for early stopping total_loss will monitor combined loss from all of
      # the tasks Criteria can also be an evaluation metric in this format `dataset/metric` for e.g.
      # vqa2/vqa_accuracy
      monitor: "train/loss"
      # Whether the monitored criteria should be minimized for early stopping or not, for e.g. you
      # would want to minimize loss but maximize an evaluation metric like accuracy etc.
      mode: "min"
      min_delta: 0.0

  # Weights and Biases control, by default Weights and Biases (wandb) is disabled
  wandb:
    # Whether to use Weights and Biases Logger, (Default: false)
    enabled: True
    # Project name to be used while logging the experiment with wandb
    project: geoscreens_${oc.env:USER}
    # Experiment/ run name to be used while logging the experiment under the project with wandb
    name: ${training.experiment_name}
    #  Log checkpoints created by
    #    :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint` as W&B artifacts.
    #    `latest` and `best` aliases are automatically set.
    #
    #      * if ``log_model == 'all'``, checkpoints are logged during training.
    #      * if ``log_model == True``, checkpoints are logged at the end of training, except when
    #        :paramref:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint.save_top_k` ``== -1``
    #        which also logs every checkpoint during training.
    #      * if ``log_model == False`` (default), no checkpoint is logged.
    log_model: True
    # Path where data is saved (wandb dir by default).
    save_dir: ${env.wandb_logdir}
    offline: False
    # Sets the version, mainly used to resume a previous run.
    id: null
    # Enables or explicitly disables anonymous logging.
    anonymous: null
    # A string to put at the beginning of metric keys.
    prefix: ""
    notes: ""
    group: ""
    job_type: ""
    entity: ""

optimizer:
  type: "adam"
  params:
    lr: 1e-4
    # betas: null
    # eps: 1e-8
    # weight_decay: 0
    # amsgrad: false

scheduler:
  type: "ReduceLROnPlateau"
  params:
    mode: "min"
    factor: 0.6
    patience: 10
    min_lr: 1e-7
    verbose: True
  config:
    # The unit of the scheduler's step size, could also be 'step'. 'epoch' updates the scheduler on
    # epoch end whereas 'step' updates it after a optimizer update.
    interval: "epoch"
    # Metric to to monitor for schedulers like `ReduceLROnPlateau`
    monitor: "train_loss"
    # If set to `True`, will enforce that the value specified 'monitor' is available when the
    # scheduler is updated, thus stopping training if not found. If set to `False`, it will only
    # produce a warning
    strict: True
    # How many epochs/steps should pass between calls to `scheduler.step()`. 1 corresponds to
    # updating the learning rate after every epoch/step.
    #
    # If "monitor" references validation metrics, then "frequency" should be set to a multiple of
    # "trainer.check_val_every_n_epoch".
    frequency: 1
    # If using the `LearningRateMonitor` callback to monitor the learning rate progress, this
    # keyword can be used to specify a custom logged name
    name: None
