{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f26a2-4e4c-4abf-999d-f5345b7aab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39379f4a-55ea-4ba0-a52b-00fa887cd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union, cast\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as pil_img\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from tqdm.contrib import tenumerate, tmap, tzip\n",
    "from tqdm.contrib.bells import tqdm, trange\n",
    "\n",
    "from geoscreens.consts import (\n",
    "    EXTRACTED_FRAMES_PATH,\n",
    "    FRAMES_METADATA_PATH,\n",
    "    LATEST_DETECTION_MODEL_NAME,\n",
    "    VIDEO_PATH,\n",
    ")\n",
    "from geoscreens.data import get_all_geoguessr_split_metadata\n",
    "from geoscreens.data.metadata import GOOGLE_SHEET_IDS, FramesList\n",
    "from geoscreens.utils import batchify, load_json, save_json, timeit_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69af1c6-e52f-401e-94c4-29a93d38255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "# Suitable default display for floats\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "\n",
    "# This one is optional -- change graphs to SVG only use if you don't have a\n",
    "# lot of points/lines in your graphs. Can also just use ['retina'] if you\n",
    "# don't want SVG.\n",
    "%config InlineBackend.figure_formats = [\"retina\"]\n",
    "set_matplotlib_formats(\"pdf\", \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e37ce27-1ad0-4cd2-90be-ec2560a305e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ffe90-9596-4bce-8ed6-1a7960119b56",
   "metadata": {},
   "source": [
    "## Show First Frames of Random Rounds & Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564275d-fc9f-4bec-9f40-58e27ea87358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, Markdown\n",
    "from PIL import ImageDraw\n",
    "\n",
    "\n",
    "def transform_box(x1, y1, x2, y2, target_width, target_height, curr_dim=640):\n",
    "    \"\"\"\n",
    "    Transform bbox coordinates from (curr_dim, curr_dim) pixel space to size=(width, height) pixel\n",
    "    space. assumes width is greater than height. This is used because the detector bbox coordinates\n",
    "    are in a square pixel space (config.dataset_config.img_size)**2, and we need to convert the bbox\n",
    "    coordinates back to the original image pixel space (e.g., 1280*720).\n",
    "\n",
    "    Args:\n",
    "        xmin, ymin, xmax, ymax\n",
    "\n",
    "    Returns:\n",
    "        Tuple[[xmin, ymin, xmax, ymax], area]\n",
    "    \"\"\"\n",
    "    # Back to width*width:\n",
    "    new_x1 = x1 * (target_width / curr_dim)\n",
    "    new_y1 = y1 * (target_width / curr_dim)\n",
    "    new_x2 = x2 * (target_width / curr_dim)\n",
    "    new_y2 = y2 * (target_width / curr_dim)\n",
    "    # Remove vertical padding\n",
    "    y_pad = (target_width - target_height) / 2\n",
    "    new_y1 -= y_pad\n",
    "    new_y2 -= y_pad\n",
    "    new_area = (new_x2 - new_x1 + 1) * (new_y2 - new_y1 + 1)\n",
    "    return (new_x1, new_y1, new_x2, new_y2), new_area\n",
    "\n",
    "\n",
    "def get_dets(video_id: str, model: str, df_meta: pd.DataFrame):\n",
    "    split = df_meta.loc[video_id].split\n",
    "    dets_path = Path(\n",
    "        f\"/shared/gbiamby/geo/segment/detections/{model}/{split}/df_frame_dets-video_id_{video_id}.pkl\"\n",
    "    )\n",
    "    df_dets = pickle.load(open(dets_path, \"rb\"))\n",
    "    if \"frame_id\" in df_dets.columns:\n",
    "        df_dets.drop(columns=[\"frame_id\"], inplace=True)\n",
    "    df_dets.set_index(\"frame_idx\", inplace=True)\n",
    "\n",
    "    # df_dets.bbox.apply(lambda x: transform_box(*x.values(),\n",
    "    return df_dets\n",
    "\n",
    "\n",
    "def show_random_frames_masked(\n",
    "    video_id: str, model: str, df: pd.DataFrame, df_meta: pd.DataFrame, n_samples: int = 5\n",
    "):\n",
    "    df_random = df.sample(n=n_samples)\n",
    "    df_dets = get_dets(video_id, model, df_meta)\n",
    "    for idx, img_row in df_random.iterrows():\n",
    "        print(\"-\" * 180)\n",
    "        print(\n",
    "            f\"video_id: {img_row.video_id}, frame_idx: {img_row.frame_idx}, seconds: {img_row.sec}\",\n",
    "        )\n",
    "        img = pil_img.open(img_row[\"file_path\"])\n",
    "        # img.thumbnail((1080, 640), pil_img.NEAREST)\n",
    "        img_width, img_height = img.size\n",
    "        display(img)\n",
    "        dets = df_dets.loc[img_row.frame_idx]\n",
    "        # display(dets)\n",
    "        dets_lookup = {\n",
    "            l: (l, transform_box(*bb.values(), img_width, img_height), s)\n",
    "            for l, bb, s in zip(dets.labels, dets.bboxes, dets.scores)\n",
    "        }\n",
    "        # print(dets_lookup)\n",
    "        masked_area = sum([d[1][1] for d in dets_lookup.values()])\n",
    "        print(\n",
    "            f\"masked_area: {masked_area:,}\",\n",
    "            f\"img_area: {float(img_width*img_height):,}\",\n",
    "            f\"pct_masked: {100.0 * masked_area / (img_width*img_height):.2f}%\",\n",
    "        )\n",
    "\n",
    "        img_masked = img\n",
    "        draw = ImageDraw.Draw(img_masked)\n",
    "        for label, bbox, score in dets_lookup.values():\n",
    "            draw.rectangle(bbox[0], fill=0)\n",
    "\n",
    "        # Mask out minimum rectangular region that encloses the geoguessr logo and/or the status bar:\n",
    "        top_ui = [dets_lookup[l] for l in [\"game_title\", \"status_bar\"] if l in dets_lookup]\n",
    "        if top_ui:\n",
    "            y_max = max(d[1][0][3] for d in top_ui)\n",
    "            # xmin, ymax = reverse_point(640, y_max, img_width, img_height, 640)\n",
    "            draw.rectangle((0, 0, img_width, y_max), fill=0)\n",
    "        display(img_masked)\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "if \"df_meta\" not in locals():\n",
    "    df_meta = pd.DataFrame(get_all_geoguessr_split_metadata().values()).set_index(\"id\")\n",
    "if \"frame_paths\" not in locals():\n",
    "    frame_paths = pickle.load(open(EXTRACTED_FRAMES_PATH / \"frames_list.pkl\", \"rb\"))\n",
    "\n",
    "\n",
    "video_id = \"--0Kbpo9DtE\"\n",
    "video_id = \"zOoUR17xnL0\"\n",
    "model = LATEST_DETECTION_MODEL_NAME\n",
    "# frames = subsample_frames(video_id, df_frames_meta, frame_paths)\n",
    "# df_all_frames = pd.DataFrame(frames)\n",
    "# in_game_frames = filter_to_in_game(video_id, frames, df_meta)\n",
    "# df_ingame = pd.DataFrame(in_game_frames).sort_values([\"round_num\", \"frame_idx\"])\n",
    "\n",
    "show_random_frames_masked(video_id, model, df_ingame.loc[video_id], df_meta, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a61359-c0de-482b-8010-9326d791d0a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Use Initial Frame(s) To Identify Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6f214-3cc8-463c-982b-6047e3d2ffd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_first_name_frames(\n",
    "    video_id: str, df_ingame: pd.DataFrame, n_samples: int = 5, round_num: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Get first n_samples frames from given round of the video\n",
    "    \"\"\"\n",
    "    video_rows = df_ingame.loc[video_id].sort_index()\n",
    "    results = []\n",
    "    rounds = set(video_rows.round_num.unique().tolist())\n",
    "    if round_num:\n",
    "        rounds = rounds.intersection(set([round_num]))\n",
    "    for round_num in rounds:\n",
    "        start, end = -1, -1\n",
    "        total_sampled = 0\n",
    "        round_rows = video_rows[video_rows.round_num == round_num]\n",
    "        for i, (idx, row) in enumerate(round_rows.iterrows()):\n",
    "            # if i<=6:\n",
    "            #     continue\n",
    "            if start < 0:\n",
    "                if True or \"in_game_mini_map\" in row.labels:\n",
    "                    start = row.frame_idx\n",
    "                else:\n",
    "                    continue\n",
    "            total_sampled += 1\n",
    "            end = row.frame_idx\n",
    "            if total_sampled > n_samples:\n",
    "                break\n",
    "            print(row)\n",
    "            img = display(pil_img.open(row.file_path))\n",
    "\n",
    "        print(f\"start: {start}, end: {end}\")\n",
    "        print(len(round_rows.loc[start:end]))\n",
    "        results.append(round_rows.loc[start:end])\n",
    "    return results\n",
    "\n",
    "\n",
    "video_id = \"zOoUR17xnL0\"\n",
    "video_id = \"--0Kbpo9DtE\"\n",
    "results = get_first_name_frames(video_id, df_ingame, n_samples=5, round_num=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f82629-02f3-47ac-85f7-3c549563481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_rows = df_ingame.loc[video_id].sort_index()\n",
    "video_rows.shape\n",
    "video_rows.round_num.unique().tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoscreens",
   "language": "python",
   "name": "geoscreens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
