{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a5625-1f4c-4162-b540-9e20d7e0f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05326610-0de5-4ac5-8b9f-c577ddd94376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "from typing import Dict, List, Optional, Tuple, Union, cast\n",
    "\n",
    "import cv2\n",
    "import decord\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import PIL.Image as pil_img\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from icevision import models, tfms\n",
    "from icevision.all import *\n",
    "from icevision.data import Dataset, DataSplitter, RandomSplitter\n",
    "from icevision.parsers.coco_parser import COCOBBoxParser\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from tqdm.contrib import tenumerate, tmap, tzip\n",
    "from tqdm.contrib.bells import tqdm, trange\n",
    "\n",
    "from geoscreens.geo_data import GeoScreensDataModule\n",
    "from geoscreens.models import get_model, load_model_from_path\n",
    "from geoscreens.modules import LightModelTorch, build_module\n",
    "from geoscreens.utils import batchify, load_json, timeit_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d4e3e-62e8-4e95-a239-5855693b3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "# Suitable default display for floats\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "\n",
    "# This one is optional -- change graphs to SVG only use if you don't have a\n",
    "# lot of points/lines in your graphs. Can also just use ['retina'] if you\n",
    "# don't want SVG.\n",
    "%config InlineBackend.figure_formats = [\"retina\"]\n",
    "set_matplotlib_formats(\"pdf\", \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02d71e-7e9e-480e-a9b9-f8b09732c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"pdf\", \"png\")\n",
    "plt.rcParams[\"savefig.dpi\"] = 75\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.rcParams[\"axes.labelsize\"] = 18\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"lines.linewidth\"] = 2.0\n",
    "plt.rcParams[\"lines.markersize\"] = 8\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = \"cm\"\n",
    "# plt.rcParams[\"text.latex.preamble\"] = \"\\\\usepackage{subdepth}, \\\\usepackage{type1cm}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d1425-64c7-499b-9b98-353f8bd71ee0",
   "metadata": {},
   "source": [
    "## Load Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b58192-0268-4b74-bba7-1f0194271c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42, workers=True)\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "config, module, model, light_model = load_model_from_path(\n",
    "    # \"/shared/gbiamby/geo/models/geoscreens_009-resnest50_fpn-with_augs/\",\n",
    "    \"/home/gbiamby/proj/geoscreens/tools/output/keep/gs_012_extra_augs_more_epochs--geoscreens_012-model_faster_rcnn-bb_resnest50_fpn-36e514692a/\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "model, light_model = model.eval(), light_model.eval()\n",
    "geoscreens_data = GeoScreensDataModule(config, module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56486d27-85b3-42b0-95c1-dfd085ae7861",
   "metadata": {},
   "source": [
    "## Show Some Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89f7a2-7754-4dd3-88c7-f0f2593b6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = geoscreens_data.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefbf18-51d6-4654-a3e3-4e2446c3414b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show an element of the train_ds with augmentation transformations applied\n",
    "samples = [train_ds[10] for _ in range(3)]\n",
    "show_samples(samples, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e674b-b20c-4078-925f-9328880d55fd",
   "metadata": {},
   "source": [
    "### Show some validation set samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb85ed-d35a-4cee-b2d9-d639cf8eded6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module.show_batch(first(geoscreens_data.val_dataloader()), ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945cfa0e-e11f-4e1e-b4da-7f501381f5c8",
   "metadata": {},
   "source": [
    "### Show some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9653ac-87a9-472e-84df-0127f3264860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "size = 30\n",
    "module.show_results(\n",
    "    light_model,\n",
    "    geoscreens_data.valid_ds,\n",
    "    num_samples=num_samples,\n",
    "    detection_threshold=0.5,\n",
    "    device=DEVICE,\n",
    "    figsize=(size, (size * num_samples) / 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52838ad7-5fa1-465c-9966-c2bf86837b0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d3e25-87b3-4305-af74-15d766578403",
   "metadata": {},
   "source": [
    "# Prediction Testing Dataloader and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7a922-074d-4125-b66a-9dfd501eae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icevision.core import ClassMap\n",
    "from icevision.core.record import BaseRecord\n",
    "from icevision.core.record_components import ClassMapRecordComponent, ImageRecordComponent\n",
    "from icevision.tfms import Transform\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class GeoscreensInferenceDataset(object):\n",
    "    \"\"\"\n",
    "    Only usable for inference.\n",
    "\n",
    "    Provides a dataset over a folder with video frames in form::\n",
    "\n",
    "        <video_id_1>/\n",
    "            frame_....jpg\n",
    "        <video_id_2>/\n",
    "            frame_....jpg\n",
    "\n",
    "    If no video_id specified, the dataset will loop over all <video_id>\n",
    "    subfolders and include all frames in each.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frames_path: Union[str, Path],\n",
    "        class_map: ClassMap,\n",
    "        video_ids: Union[int, List[int]] = None,\n",
    "        tfm: Optional[Transform] = None,\n",
    "    ):\n",
    "        self.frames_path = Path(frames_path).resolve()\n",
    "        assert self.frames_path.exists(), f\"Frames path not found: {self.frames_path}\"\n",
    "        assert self.frames_path.is_dir(), f\"Frames path is not a directory: {self.frames_path}\"\n",
    "        if video_ids and isinstance(video_ids, str):\n",
    "            video_ids = [video_ids]\n",
    "        elif video_ids is None:\n",
    "            video_ids = []\n",
    "        self.tfm = tfm\n",
    "        self.class_map = class_map\n",
    "        self.frames = []\n",
    "        record_id: int = 0\n",
    "        print(\"video_ids\")\n",
    "        for video_id in video_ids:\n",
    "            frames = sorted((self.frames_path / video_id).glob(\"*.jpg\"))\n",
    "            print(\"Num frames found: \", len(frames))\n",
    "            for f in frames:\n",
    "                record = BaseRecord((ImageRecordComponent(),))\n",
    "                record.set_record_id(record_id)\n",
    "                # record.set_img(image)\n",
    "\n",
    "                # TODO, HACK: adding class map because of `convert_raw_prediction`\n",
    "                record.add_component(ClassMapRecordComponent(task=tasks.detection))\n",
    "                if class_map is not None:\n",
    "                    record.detection.set_class_map(class_map)\n",
    "                parts = f.stem.replace(\"frame_\", \"\").replace(\"s\", \"\").split(\"-\")\n",
    "                self.frames.append(\n",
    "                    {\n",
    "                        \"video_id\": video_id,\n",
    "                        \"frame_idx\": -1,\n",
    "                        \"file_path\": f,\n",
    "                        \"frame_idx\": int(parts[0]),\n",
    "                        \"seconds\": round(float(parts[1]), 2),\n",
    "                        \"record\": record,\n",
    "                    }\n",
    "                )\n",
    "                record_id += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        meta = self.frames[i]\n",
    "        record = meta[\"record\"]\n",
    "        img = np.array(Image.open(str(meta[\"file_path\"])))\n",
    "        record.set_img(img)\n",
    "        record.load()\n",
    "        if self.tfm is not None:\n",
    "            record = self.tfm(record)\n",
    "        # else:\n",
    "        #     # HACK FIXME\n",
    "        #     # record.set_img(np.array(record.img))\n",
    "        #     pass\n",
    "        return record\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.__class__.__name__} with {len(self.records)} items>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0a28d-33a0-4fb1-b6a7-72cab5995833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# video_path = Path(\"/shared/gbiamby/geo/video_frames/pF9OA332DPk.mp4\")\n",
    "frames_path = \"/shared/gbiamby/geo/video_frames\"\n",
    "infer_tfms = tfms.A.Adapter(\n",
    "    [*tfms.A.resize_and_pad(config.dataset_config.img_size), tfms.A.Normalize()]\n",
    ")\n",
    "infer_ds = GeoscreensFramesDataset(\n",
    "    frames_path, geoscreens_data.parser.class_map, \"pF9OA332DPk\", infer_tfms\n",
    ")\n",
    "infer_dl = module.infer_dl(infer_ds, batch_size=8, shuffle=False, num_workers=16)\n",
    "\n",
    "print(\"len ds: \", len(infer_ds))\n",
    "preds = module.predict_from_dl(model, infer_dl, detection_threshold=0.5)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106b56d-0833-47d7-a76c-7b5b0b16c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360c36e-a130-4b85-a590-affa5f9cb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = \"frame_00039798-001326.600s.jpg\"\n",
    "parts = f_name.replace(\"frame_\", \"\").replace(\".jpg\", \"\").split(\"-\")\n",
    "frame_idx = int(parts[0])\n",
    "seconds = round(float(parts[1].replace(\"s\", \"\")), 2)\n",
    "frame_idx, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288ebce-e656-4a07-91f9-615f15c9fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections_from_generator():\n",
    "    raw_frames = [np.array(frame)]\n",
    "    infer_ds = Dataset.from_images(\n",
    "        raw_frames, infer_tfms, class_map=geoscreens_data.parser.class_map\n",
    "    )\n",
    "    preds = module.predict(model, infer_ds, detection_threshold=0.5)\n",
    "    if preds:\n",
    "        assert len(preds) == 1, \"Expected list of size 1.\"\n",
    "        preds = preds[0]\n",
    "        detections[frame_counter] = {\n",
    "            \"label_ids\": [int(l) for l in preds.detection.label_ids],\n",
    "            \"scores\": preds.detection.scores.tolist(),\n",
    "            \"bboxes\": [\n",
    "                {\n",
    "                    \"xmin\": float(box.xmin),\n",
    "                    \"ymin\": float(box.ymin),\n",
    "                    \"xmax\": float(box.xmax),\n",
    "                    \"ymax\": float(box.ymax),\n",
    "                }\n",
    "                for box in preds.detection.bboxes\n",
    "            ],\n",
    "        }\n",
    "\n",
    "\n",
    "@timeit_context(\"\")\n",
    "def get_frames_wrapper(fn, config, video_path):\n",
    "    return [f for f in fn(config, video_path)]\n",
    "\n",
    "\n",
    "def get_indices_to_sample(config, total_frames: int, fps: float) -> List[int]:\n",
    "    indices = map(\n",
    "        int,\n",
    "        np.linspace(\n",
    "            start=0.0,\n",
    "            stop=total_frames,\n",
    "            num=int(total_frames * (config.frame_sample_rate_fps / fps)),\n",
    "            retstep=False,\n",
    "            endpoint=False,\n",
    "        ),\n",
    "    )\n",
    "    return list(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c8ac29-7721-4b24-b266-c35c84131a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_frames_generator_opencv(\n",
    "#     config: DictConfig,\n",
    "#     video_path: Path,\n",
    "# ):\n",
    "#     print(\"Segmenting video: \", video_path)\n",
    "#     error_state = False\n",
    "#     cap = cv2.VideoCapture(str(video_path))\n",
    "#     if not cap.isOpened():\n",
    "#         print(\"Error opening input video: {}\".format(video_path))\n",
    "#         return\n",
    "\n",
    "#     num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     sample_indices = get_indices_to_sample(config, num_frames, fps)\n",
    "#     print(f\"total_frames: {num_frames:,}, num_to_sample: {len(sample_indices):,}, fps: {fps}\")\n",
    "#     print(\"config.frame_sample_rate_fps: \", config.frame_sample_rate_fps)\n",
    "#     for frame_counter in tqdm(range(len(sample_indices)), total=len(sample_indices)):\n",
    "#         frame_idx = sample_indices[frame_counter]\n",
    "#         if config.fast_debug and frame_counter >= config.debug_max_frames:\n",
    "#             break\n",
    "#         seconds = frame_idx / fps\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC, (seconds * 1000))\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             raise Error(f\"Error while processing video_id: {video_path} (ret:{ret}\")\n",
    "#             break\n",
    "#         yield (seconds, frame_idx, frame)\n",
    "\n",
    "\n",
    "# video_path = Path(\"/home/gbiamby/proj/geoscreens/data/videos/pF9OA332DPk.mp4\")\n",
    "# config = DictConfig(\n",
    "#     {\n",
    "#         \"frame_sample_rate_fps\": 4.0,\n",
    "#         \"fast_debug\": False,\n",
    "#         \"debug_max_frames\": 300,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# frames_cv = get_frames_wrapper(get_frames_generator_opencv, config, video_path)\n",
    "# print(\"num_frames sampled: \", len(frames_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba844417-4b07-40b7-bda0-dad7c0050315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from decord import VideoReader, cpu, gpu\n",
    "\n",
    "\n",
    "def get_frames_generator_decord(config, video_path):\n",
    "    vr = VideoReader(str(video_path), ctx=cpu(0))\n",
    "    sample_indices = get_indices_to_sample(config, len(vr), vr.get_avg_fps())\n",
    "    print(\n",
    "        f\"num_frames: {len(vr):,}, num_to_sample: {len(sample_indices):,}, fps: {vr.get_avg_fps()}\"\n",
    "    )\n",
    "    print(\"config.frame_sample_rate: \", config.frame_sample_rate_fps)\n",
    "    for sample_idx in tqdm(range(len(sample_indices)), total=len(sample_indices)):\n",
    "        frame_idx = sample_indices[sample_idx]\n",
    "        if config.fast_debug and sample_idx >= config.debug_max_frames:\n",
    "            break\n",
    "        frame = vr[frame_idx]\n",
    "        seconds = round(frame_idx / vr.get_avg_fps(), 2)\n",
    "        yield (frame_idx, seconds, frame)\n",
    "\n",
    "\n",
    "# video_path = Path(\"/home/gbiamby/proj/geoscreens/data/videos/pF9OA332DPk.mp4\")\n",
    "# config = DictConfig(\n",
    "#     {\n",
    "#         \"frame_sample_rate_fps\": 4.0,\n",
    "#         \"fast_debug\": True,\n",
    "#         \"debug_max_frames\": 30,\n",
    "#         \"video_frames_path\": \"/home/gbiamby/proj/geoscreens/data/video_frames\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# frames_decord = get_frames_wrapper(get_frames_generator_decord, config, video_path)\n",
    "# print(\"num_frames sampled: \", len(frames_decord))\n",
    "# frames_decord[:10], frames_decord[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d1410-e22f-43cf-8873-164a4a730c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "@timeit_context(\"extract_frames\")\n",
    "def extract_frames(config: DictConfig, video_path: Path, get_frames_fn: Callable):\n",
    "    frames_path = Path(config.video_frames_path) / video_path.stem\n",
    "    frames_path.mkdir(exist_ok=True, parents=True)\n",
    "    print(\"Saving frames to: \", frames_path)\n",
    "    for frame_idx, seconds, frame in get_frames_fn(config, video_path):\n",
    "        frame_out_path = frames_path / f\"frame_{frame_idx:08}-{seconds:010.3f}s.jpg\"\n",
    "        cv2.imwrite(str(frame_out_path), cv2.cvtColor(frame.asnumpy(), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "video_path = Path(\"/shared/g-luo/geoguessr/videos/pF9OA332DPk.mp4\")\n",
    "config = DictConfig(\n",
    "    {\n",
    "        \"frame_sample_rate_fps\": 4.0,\n",
    "        \"fast_debug\": False,\n",
    "        \"debug_max_frames\": 30,\n",
    "        \"video_frames_path\": \"/shared/gbiamby/geo/video_frames\",\n",
    "    }\n",
    ")\n",
    "extract_frames(config, video_path, get_frames_generator_decord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f033b39-7114-4d77-ad87-8d34f2efbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def extract_frames_fake(config: DictConfig, video_path: Path, get_frames_fn: Callable):\n",
    "    frames_path = Path(config.video_frames_path) / video_path.stem\n",
    "    frames_path.mkdir(exist_ok=True, parents=True)\n",
    "    print(\"Saving frames to: \", frames_path)\n",
    "\n",
    "\n",
    "def process_videos_muli_cpu(config: DictConfig):\n",
    "    files = sorted(Path(config.videos_path).glob(\"*.mp4\"))\n",
    "    print(len(files))\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        result = pool.map(extract_frames_fake, (config, files))\n",
    "        print(result.get(timeout=1))\n",
    "\n",
    "\n",
    "config = DictConfig(\n",
    "    {\n",
    "        \"frame_sample_rate_fps\": 4.0,\n",
    "        \"fast_debug\": False,\n",
    "        \"debug_max_frames\": 30,\n",
    "        \"video_frames_path\": \"/shared/gbiamby/geo/video_frames\",\n",
    "        \"videos_path\": \"/shared/g-luo/geoguessr/videos\",\n",
    "        \"num_workers\": 4,\n",
    "    }\n",
    ")\n",
    "process_videos_muli_cpu(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c109fef-196a-4f62-84a1-ccf8cdf0a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geoscreens.utils import timeit_context\n",
    "\n",
    "\n",
    "# # Using the decord batching is somehow slower than just using the VideoReader indexing, i.e,\n",
    "# # get_frames_generator_decord().\n",
    "# @timeit_context(\"get_frames_generator_decord_batched\")\n",
    "# def get_frames_generator_decord_batched(config, video_path):\n",
    "#     vr = VideoReader(str(video_path), ctx=cpu(0))\n",
    "#     indices = get_indices_to_sample(config, len(vr), vr.get_avg_fps())\n",
    "\n",
    "#     print(f\"num_frames: {len(vr):,}, fps: {vr.get_avg_fps()}\")\n",
    "#     print(\"config.frame_sample_rate: \", config.frame_sample_rate_fps)\n",
    "\n",
    "#     if config.fast_debug and len(indices) > config.debug_max_frames:\n",
    "#         indices = indices[: config.debug_max_frames]\n",
    "#     frames = vr.get_batch(indices).asnumpy()\n",
    "#     yield from frames\n",
    "\n",
    "\n",
    "# video_path = Path(\"/shared/g-luo/geoguessr/videos/pF9OA332DPk.mp4\")\n",
    "# config = DictConfig(\n",
    "#     {\n",
    "#         \"frame_sample_rate_fps\": 4.0,\n",
    "#         \"fast_debug\": True,\n",
    "#         \"debug_max_frames\": 10000,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# frames = get_frames_wrapper(get_frames_generator_decord_batched, config, video_path)\n",
    "# print(\"num_frames sampled: \", len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848eb42-1920-41c5-bf92-0e92441af299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get multiple frames at once, use get_batch\n",
    "# this is the efficient way to obtain a long list of frames\n",
    "frames = vr.get_batch([1, 3, 5, 7, 9])\n",
    "print(frames.shape)\n",
    "# (5, 240, 320, 3)\n",
    "# duplicate frame indices will be accepted and handled internally to avoid duplicate decoding\n",
    "frames2 = vr.get_batch([1, 2, 3, 2, 3, 4, 3, 4, 5]).asnumpy()\n",
    "print(frames2.shape)\n",
    "# (9, 240, 320, 3)\n",
    "\n",
    "# 2. you can do cv2 style reading as well\n",
    "# skip 100 frames\n",
    "vr.skip_frames(100)\n",
    "# seek to start\n",
    "vr.seek(0)\n",
    "batch = vr.next()\n",
    "print(\"frame shape:\", batch.shape)\n",
    "print(\"numpy frames:\", batch.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b844fe5-9f86-4625-a9d7-6b9bf76e9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import transforms as t\n",
    "# from torchvision.datasets.folder import make_dataset\n",
    "\n",
    "\n",
    "# def get_samples(root, extensions=(\".mp4\", \".avi\")):\n",
    "#     _, class_to_idx = _find_classes(root)\n",
    "#     return make_dataset(root, class_to_idx, extensions=extensions)\n",
    "\n",
    "\n",
    "# class RandomDataset(torch.utils.data.IterableDataset):\n",
    "#     def __init__(\n",
    "#         self, root, epoch_size=None, frame_transform=None, video_transform=None, clip_len=16,\n",
    "#         video_id: str =\n",
    "#     ):\n",
    "#         super(RandomDataset).__init__()\n",
    "\n",
    "#         self.samples = []\n",
    "\n",
    "#         # Allow for temporal jittering\n",
    "#         if epoch_size is None:\n",
    "#             epoch_size = len(self.samples)\n",
    "#         self.epoch_size = epoch_size\n",
    "\n",
    "#         self.clip_len = clip_len\n",
    "#         self.frame_transform = frame_transform\n",
    "#         self.video_transform = video_transform\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for i in range(self.epoch_size):\n",
    "#             # Get random sample\n",
    "#             path, target = random.choice(self.samples)\n",
    "#             # Get video object\n",
    "#             vid = torchvision.io.VideoReader(path, \"video\")\n",
    "#             metadata = vid.get_metadata()\n",
    "#             video_frames = []  # video frame buffer\n",
    "\n",
    "#             # Seek and return frames\n",
    "#             max_seek = metadata[\"video\"][\"duration\"][0] - (\n",
    "#                 self.clip_len / metadata[\"video\"][\"fps\"][0]\n",
    "#             )\n",
    "#             start = random.uniform(0.0, max_seek)\n",
    "#             for frame in itertools.islice(vid.seek(start), self.clip_len):\n",
    "#                 video_frames.append(self.frame_transform(frame[\"data\"]))\n",
    "#                 current_pts = frame[\"pts\"]\n",
    "#             # Stack it into a tensor\n",
    "#             video = torch.stack(video_frames, 0)\n",
    "#             if self.video_transform:\n",
    "#                 video = self.video_transform(video)\n",
    "#             output = {\n",
    "#                 \"path\": path,\n",
    "#                 \"video\": video,\n",
    "#                 \"target\": target,\n",
    "#                 \"start\": start,\n",
    "#                 \"end\": current_pts,\n",
    "#             }\n",
    "#             yield output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcecc8-3fa9-40e0-9f69-ceaba21c06f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9fa07-0547-46ee-bd59-3d182ca17515",
   "metadata": {},
   "source": [
    "## Naive Detection of Bad Ground Truth Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2109275-fd88-4c2e-b7c2-ee605a6b1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = json.load(\n",
    "    open(\"/shared/gbiamby/geo/exports/geoscreens_009-from_proj_id_58.json\", \"r\", encoding=\"utf-8\")\n",
    ")\n",
    "\n",
    "mistakes = []\n",
    "for i, t in enumerate(tqdm(tasks, total=len(tasks))):\n",
    "    # if i >= 10:\n",
    "    #     break\n",
    "    # print(\"\")\n",
    "    anns_results = [ann[\"result\"] for ann in t[\"annotations\"]]\n",
    "    # print(anns_results)\n",
    "    # print([ann for ann in anns_results])\n",
    "    labels = [ann[\"value\"][\"rectanglelabels\"][0] for ann in anns_results[0]]\n",
    "    if len(labels) != len(set(labels)):\n",
    "        mistakes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9a4b5-2af9-4cf3-8c13-202c26edd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ec663-a9c1-40a8-bae0-5327f5f0cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[m[\"data\"] for m in mistakes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ca932-1a9f-4f49-9761-88b107395288",
   "metadata": {},
   "outputs": [],
   "source": [
    "[m[\"data\"] for m in mistakes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5729b8-ab14-42d1-a3e5-1461e7b59763",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(tqdm(tasks, total=len(tasks))):\n",
    "    # if i >= 10:\n",
    "    #     break\n",
    "    if \"aob8sh6l-6M/frame_00000221\" in t[\"data\"][\"image\"]:\n",
    "        print(\"\")\n",
    "        print(t[\"id\"], t[\"data\"][\"image\"])\n",
    "        anns_results = [ann[\"result\"] for ann in t[\"annotations\"]]\n",
    "        print(\"anns_results: \", anns_results, len(anns_results))\n",
    "        labels = [ann[\"value\"][\"rectanglelabels\"][0] for ann in anns_results[0]]\n",
    "        print(\"labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd322e6-88b6-428a-9d2e-0fed0232a0e3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scratch / Junk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec502d-ac73-4b03-85d4-f072b83726cc",
   "metadata": {},
   "source": [
    "### Find/FIlter Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5d2f1-42e0-4147-9e0b-275d00bb3513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_task = defaultdict(list)\n",
    "for t in tasks:\n",
    "    path_to_task[t[\"data\"][\"full_path\"]].append(t)\n",
    "print(len(tasks), len(path_to_task))\n",
    "\n",
    "c = Counter([t[\"data\"][\"full_path\"] for t in tasks])\n",
    "dupes = [k for k, v in c.items() if v > 1]\n",
    "\n",
    "print(\"total dupes: \", len(dupes))\n",
    "to_remove = []\n",
    "for path in dupes:\n",
    "    print(\"\")\n",
    "    print(\"=\" * 100)\n",
    "    task_blobs = [json.dumps(t, sort_keys=True) for t in path_to_task[path]]\n",
    "    ann_ids = [t[\"id\"] for t in path_to_task[path]]\n",
    "    max_id = max(ann_ids)\n",
    "    # print(\"ann_ids: \", path_to_task[path])\n",
    "    print(\"ann_ids: \", ann_ids)\n",
    "    # for t in task_blobs:\n",
    "    #     print(\"\")\n",
    "    #     print(t)\n",
    "    print(\"Removing: \")\n",
    "    for t in path_to_task[path]:\n",
    "        if t[\"id\"] != max_id:\n",
    "            print(\"Removing task_id: \", t[\"id\"])\n",
    "            to_remove.append((t[\"id\"], path))\n",
    "\n",
    "to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a6693-ca0c-4337-9b5b-76f94206fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_filtered = []\n",
    "\n",
    "for t in tasks:\n",
    "    if (t[\"id\"], t[\"data\"][\"full_path\"]) in to_remove:\n",
    "        continue\n",
    "    tasks_filtered.append(t)\n",
    "\n",
    "print(len(tasks), len(tasks_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac263f-0798-4c5a-a462-358391115171",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ecf188-099f-4d09-b400-0617cd535885",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(\n",
    "    tasks_filtered,\n",
    "    open(Path(\"/shared/gbiamby/geo/geoscreens_004_tasks_with_preds.json\"), \"w\"),\n",
    "    indent=4,\n",
    "    sort_keys=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab5b54-3531-467e-acc9-e7127041d14c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489da9d1-b4be-454c-aa5a-b76d7a2e9a4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68cf1b1-a458-4669-8499-2bce301e9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "213 % 10, 213 // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e54f1-478e-42b4-8b67-22e6a4538219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoscreens",
   "language": "python",
   "name": "geoscreens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
