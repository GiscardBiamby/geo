{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06fc10-6f31-48df-9c3e-8db0bb995111",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ed977-0b40-4496-914f-505f8ceec73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union, cast\n",
    "\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as pil_img\n",
    "from IPython.display import display\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from tqdm.contrib import tenumerate\n",
    "from tqdm.contrib.bells import tqdm\n",
    "\n",
    "from geoscreens.consts import (\n",
    "    EXTRACTED_FRAMES_PATH,\n",
    "    FRAMES_METADATA_PATH,\n",
    "    LATEST_DETECTION_MODEL_NAME,\n",
    "    VIDEO_PATH,\n",
    ")\n",
    "from geoscreens.data import get_all_geoguessr_split_metadata\n",
    "from geoscreens.data.metadata import GOOGLE_SHEET_IDS, FramesList\n",
    "from geoscreens.utils import load_json, save_json, timeit_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046041c-66ed-4d8d-accc-cdec90aa2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "# Suitable default display for floats\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "\n",
    "# This one is optional -- change graphs to SVG only use if you don't have a\n",
    "# lot of points/lines in your graphs. Can also just use ['retina'] if you\n",
    "# don't want SVG.\n",
    "%config InlineBackend.figure_formats = [\"retina\"]\n",
    "set_matplotlib_formats(\"pdf\", \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41f0cc-eb15-41c2-ab1c-8d598fca1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"pdf\", \"png\")\n",
    "plt.rcParams[\"savefig.dpi\"] = 75\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.rcParams[\"axes.labelsize\"] = 18\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"lines.linewidth\"] = 2.0\n",
    "plt.rcParams[\"lines.markersize\"] = 8\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = \"cm\"\n",
    "plt.rcParams[\"text.latex.preamble\"] = \"\\\\usepackage{subdepth}, \\\\usepackage{type1cm}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151ea53-0296-4aab-b31b-a96426a470e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_frames_meta = pd.read_json(\n",
    "#     FRAMES_METADATA_PATH,\n",
    "#     orient=\"index\"\n",
    "# )\n",
    "# # df_frames_meta.describe()\n",
    "# display(df_frames_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdb1fa-cddd-4e37-be94-bfdd5c9e0f39",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cad73-29d0-446a-bd57-78bb3a4e2b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_box(x1, y1, x2, y2, target_width, target_height, curr_dim=640):\n",
    "    \"\"\"\n",
    "    Transform bbox coordinates from (curr_dim, curr_dim) pixel space to size=(width, height) pixel\n",
    "    space. assumes width is greater than height. This is used because the detector bbox coordinates\n",
    "    are in a square pixel space (config.dataset_config.img_size)**2, and we need to convert the bbox\n",
    "    coordinates back to the original image pixel space (e.g., 1280*720).\n",
    "\n",
    "    Args:\n",
    "        xmin, ymin, xmax, ymax\n",
    "\n",
    "    Returns:\n",
    "        Tuple[[xmin, ymin, xmax, ymax], area]\n",
    "    \"\"\"\n",
    "    # Back to width*width:\n",
    "    new_x1 = x1 * (target_width / curr_dim)\n",
    "    new_y1 = y1 * (target_width / curr_dim)\n",
    "    new_x2 = x2 * (target_width / curr_dim)\n",
    "    new_y2 = y2 * (target_width / curr_dim)\n",
    "    # Remove vertical padding\n",
    "    y_pad = (target_width - target_height) / 2\n",
    "    new_y1 -= y_pad\n",
    "    new_y2 -= y_pad\n",
    "    new_area = (new_x2 - new_x1 + 1) * (new_y2 - new_y1 + 1)\n",
    "    return (new_x1, new_y1, new_x2, new_y2), new_area\n",
    "\n",
    "\n",
    "def subsample_frames(\n",
    "    video_id: str,\n",
    "    df_frames_meta: pd.DataFrame,\n",
    "    frame_paths: dict[str, list[dict[str, str]]],\n",
    "    target_fps: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Subsample to 1 fps From existing frames on disk, which are extracted from\n",
    "    original videos at 4.0fps and used to detect UI elements and compute the\n",
    "    in/out-of-game segments. So this sub-samples at something higher since we\n",
    "    don't need that high of a temporal resolution for im2clue training.\n",
    "\n",
    "    Args:\n",
    "        target_fps: This is how many  fps you want to sample from the existing\n",
    "            jpg's. It should be a subset of `frame_sample_rate_fps`, which is the\n",
    "            rate that the frames on disk were sampled at.\n",
    "    \"\"\"\n",
    "    # This is how many fps the jpg's were sampled at:\n",
    "    frames_fps = df_frames_meta.loc[video_id].frame_sample_rate_fps\n",
    "    assert (\n",
    "        frames_fps % target_fps == 0.0\n",
    "    ), f\"frames_fps {frames_fps} should be divisible by target_fps {target_fps}\"\n",
    "    video_frames = [Path(f[\"file_path\"]) for f in frame_paths[video_id]]\n",
    "    return [\n",
    "        {\n",
    "            \"video_id\": video_id,\n",
    "            \"frame_idx\": int(f.stem.replace(\"frame_\", \"\").replace(\"s\", \"\").split(\"-\")[0]),\n",
    "            \"sec\": float(f.stem.replace(\"frame_\", \"\").replace(\"s\", \"\").split(\"-\")[1]),\n",
    "            \"file_path\": EXTRACTED_FRAMES_PATH / f,\n",
    "        }\n",
    "        for i, f in enumerate(video_frames)\n",
    "        if i % int(frames_fps / target_fps) == 0\n",
    "    ]\n",
    "\n",
    "\n",
    "def filter_to_in_game(\n",
    "    video_id: str, frames: List[Dict[str, Any]], df_meta: pd.DataFrame\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Limit frames to \"in_game\" segments\n",
    "    \"\"\"\n",
    "    split = df_meta.loc[video_id].split\n",
    "    seg_file = Path(f\"/shared/gbiamby/geo/segment/seg/{split}/df_seg-video_id_{video_id}.pkl\")\n",
    "    df_seg = pickle.load(open(seg_file, \"rb\"))\n",
    "    df_seg = df_seg[df_seg.state == \"in_game\"].reset_index(drop=True)\n",
    "    in_games = [(idx, r[\"start_frame_idx\"], r[\"end_frame_idx\"]) for idx, r in df_seg.iterrows()]\n",
    "\n",
    "    def is_in_game(frame):\n",
    "        for seg in in_games:\n",
    "            if seg[1] <= frame[\"frame_idx\"] <= seg[2]:\n",
    "                frame[\"round_num\"] = seg[0]\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    frames = [frame for frame in frames if is_in_game(frame)]\n",
    "    if frames:\n",
    "        img = pil_img.open(frames[0][\"file_path\"])\n",
    "        img_width, img_height = img.size\n",
    "        for f in frames:\n",
    "            f[\"img_width\"] = img_width\n",
    "            f[\"img_height\"] = img_height\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def get_dets(video_id: str, model: str, df_meta: pd.DataFrame):\n",
    "    split = df_meta.loc[video_id].split\n",
    "    dets_path = Path(\n",
    "        f\"/shared/gbiamby/geo/segment/detections/{model}/{split}/df_frame_dets-video_id_{video_id}.pkl\"\n",
    "    )\n",
    "    df_dets = pickle.load(open(dets_path, \"rb\"))\n",
    "    if \"frame_id\" in df_dets.columns:\n",
    "        df_dets.drop(columns=[\"frame_id\"], inplace=True)\n",
    "    df_dets.set_index(\"frame_idx\", inplace=True)\n",
    "\n",
    "    # df_dets.bbox.apply(lambda x: transform_box(*x.values(),\n",
    "    return df_dets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0bf16-4f50-41a7-bfae-b30d14a5b73f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdaf43-5392-44f3-a3c9-975161ea30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_game_frames = filter_to_in_game(video_id, frames)\n",
    "# print(len(frames), len(in_game_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023a1a8-7c23-4990-ace0-75a0151a9d89",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e0640-2189-42e9-8493-e75e6c7b368f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test a Single Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d742fbe-3407-4022-80ad-fbe337365cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_id = \"--0Kbpo9DtE\"\n",
    "video_id = \"zOoUR17xnL0\"\n",
    "\n",
    "if \"df_meta\" not in locals():\n",
    "    df_meta = pd.DataFrame(get_all_geoguessr_split_metadata().values()).set_index(\"id\")\n",
    "if \"frame_paths\" not in locals():\n",
    "    frame_paths = pickle.load(open(EXTRACTED_FRAMES_PATH / \"frames_list.pkl\", \"rb\"))\n",
    "\n",
    "frames = subsample_frames(video_id, df_frames_meta, frames_list)\n",
    "print(len(frames))\n",
    "df_all_frames = pd.DataFrame(frames)\n",
    "in_game_frames = filter_to_in_game(video_id, frames, df_meta)\n",
    "print(f\"num frames: {len(frames)}, num in_game frames: {len(in_game_frames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76942ed0-e2ba-434b-90a1-e57b94e98206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ingame = pd.DataFrame(in_game_frames).sort_values([\"round_num\", \"frame_idx\"])\n",
    "# display(df_ingame)\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        df_ingame.groupby([\"round_num\"]).agg(\n",
    "            total_frames=(\"frame_idx\", \"count\"),\n",
    "            start_sec=(\"sec\", \"min\"),\n",
    "            end_sec=(\"sec\", \"max\"),\n",
    "            start_frame=(\"frame_idx\", \"min\"),\n",
    "            end_frame=(\"frame_idx\", \"max\"),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70afc89-53eb-4466-9b1b-74ba5c452525",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Show Some in_game Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7c523-588d-4eb3-95ac-37a07effe674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ingame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb86e2-bcb3-4766-ac8c-626dd8bad61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, Markdown\n",
    "\n",
    "\n",
    "def show_random_frames(df: pd.DataFrame, n_samples: int = 5):\n",
    "    df_random = df.sample(n=n_samples)\n",
    "\n",
    "    for idx, img_row in df_random.iterrows():\n",
    "        print(\"-\" * 180)\n",
    "        img = pil_img.open(img_row[\"file_path\"])\n",
    "        img.thumbnail((1080, 640), pil_img.NEAREST)\n",
    "        display(img)\n",
    "        print(\n",
    "            f\"video_id: {img_row.video_id}, frame_idx: {img_row.frame_idx}, seconds: {img_row.sec}\",\n",
    "        )\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "show_random_frames(df_ingame, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e35810-e2e2-45ef-889e-23426d809dd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Show Some Random Masked Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d897970-145d-42d0-aada-e029fae1255d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "\n",
    "def show_random_frames_masked(\n",
    "    video_id: str, model: str, df: pd.DataFrame, df_meta: pd.DataFrame, n_samples: int = 5\n",
    "):\n",
    "    df_random = df.sample(n=n_samples)\n",
    "    df_dets = get_dets(video_id, model, df_meta)\n",
    "    for idx, img_row in df_random.iterrows():\n",
    "        print(\"-\" * 180)\n",
    "        print(\n",
    "            f\"video_id: {img_row.video_id}, frame_idx: {img_row.frame_idx}, seconds: {img_row.sec}\",\n",
    "        )\n",
    "        img = pil_img.open(img_row[\"file_path\"])\n",
    "        # img.thumbnail((1080, 640), pil_img.NEAREST)\n",
    "        img_width, img_height = img.size\n",
    "        display(img)\n",
    "        dets = df_dets.loc[img_row.frame_idx]\n",
    "        # display(dets)\n",
    "        dets_lookup = {\n",
    "            l: (l, transform_box(*bb.values(), img_width, img_height), s)\n",
    "            for l, bb, s in zip(dets.labels, dets.bboxes, dets.scores)\n",
    "        }\n",
    "        # print(dets_lookup)\n",
    "        masked_area = sum([d[1][1] for d in dets_lookup.values()])\n",
    "        print(\n",
    "            f\"masked_area: {masked_area:,}\",\n",
    "            f\"img_area: {float(img_width*img_height):,}\",\n",
    "            f\"pct_masked: {100.0 * masked_area / (img_width*img_height):.2f}%\",\n",
    "        )\n",
    "\n",
    "        img_masked = img\n",
    "        draw = ImageDraw.Draw(img_masked)\n",
    "        for label, bbox, score in dets_lookup.values():\n",
    "            draw.rectangle(bbox[0], fill=0)\n",
    "\n",
    "        # Mask out minimum rectangular region that encloses the geoguessr logo and/or the status bar:\n",
    "        top_ui = [dets_lookup[l] for l in [\"game_title\", \"status_bar\"] if l in dets_lookup]\n",
    "        if top_ui:\n",
    "            y_max = max(d[1][0][3] for d in top_ui)\n",
    "            # xmin, ymax = reverse_point(640, y_max, img_width, img_height, 640)\n",
    "            draw.rectangle((0, 0, img_width, y_max), fill=0)\n",
    "        display(img_masked)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42ceb2-80be-4a07-b302-e0765cf88de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"df_meta\" not in locals():\n",
    "    df_meta = pd.DataFrame(get_all_geoguessr_split_metadata().values()).set_index(\"id\")\n",
    "if \"frame_paths\" not in locals():\n",
    "    frame_paths = pickle.load(open(EXTRACTED_FRAMES_PATH / \"frames_list.pkl\", \"rb\"))\n",
    "\n",
    "video_id = \"--0Kbpo9DtE\"\n",
    "# video_id = \"zOoUR17xnL0\"\n",
    "model = LATEST_DETECTION_MODEL_NAME\n",
    "frames = subsample_frames(video_id, df_frames_meta, frame_paths)\n",
    "df_all_frames = pd.DataFrame(frames)\n",
    "in_game_frames = filter_to_in_game(video_id, frames, df_meta)\n",
    "df_ingame = pd.DataFrame(in_game_frames).sort_values([\"round_num\", \"frame_idx\"])\n",
    "\n",
    "show_random_frames_masked(video_id, model, df_ingame, df_meta, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be87b0-dc74-4fae-9ea4-59df8ca2c0ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f302152-e67a-4581-9a34-d604b79d5df8",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949cb26-931b-4836-808e-70269a813e2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some Stats about Video -> Frames, CLIP Samples Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b835f1-f978-49e4-8d85-349478f79bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_list = deepcopy(GOOGLE_SHEET_IDS)\n",
    "print(\"ids_list.len: \", len(id_list))\n",
    "\n",
    "if \"df_meta\" not in locals():\n",
    "    df_meta = pd.DataFrame(get_all_geoguessr_split_metadata().values()).set_index(\"id\")\n",
    "# df_meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebae4d-c29c-41d0-9bf6-6b5e9fd3146d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_files = sorted(p for p in os.listdir(\"/shared/g-luo/geoguessr/videos\") if p.endswith(\".mp4\"))\n",
    "ids_with_meta = [i for i in id_list if i in df_meta.index]\n",
    "model = LATEST_DETECTION_MODEL_NAME\n",
    "# frames_extracted = [\n",
    "#     str(p.stem.replace(\"df_frame_dets-video_id_\", \"\"))\n",
    "#     for p in sorted(Path(f\"/shared/gbiamby/geo/video_frames\").glob(\"*/\"))\n",
    "# ]\n",
    "frames_extracted = [p for p in FramesList().get().keys()]\n",
    "dets = [\n",
    "    str(p.stem.replace(\"df_frame_dets-video_id_\", \"\"))\n",
    "    for p in sorted(Path(f\"/shared/gbiamby/geo/segment/detections/{model}\").glob(\"**/*.pkl\"))\n",
    "]\n",
    "segs = [\n",
    "    str(p.stem.replace(\"df_seg-video_id_\", \"\"))\n",
    "    for p in sorted(Path(\"/shared/gbiamby/geo/segment/seg\").glob(\"**/*.pkl\"))\n",
    "]\n",
    "ids_with_dets = [i for i in ids_with_meta if i in dets]\n",
    "ids_with_segs = [i for i in ids_with_dets if i in segs]\n",
    "ids_with_frames = []\n",
    "print(\"\")\n",
    "print(f\"Total video files: {len(video_files):,}\")\n",
    "print(f\"Videos w/ metadata: {len(df_meta):,}\")\n",
    "print(\"Videos w/ frames extracted: \", len(frames_extracted))\n",
    "print(\"Videos w/ UI detection outputs: \", len(dets))\n",
    "print(\"Videos w/ segmentation outputs: \", len(segs))\n",
    "\n",
    "print(\"\")\n",
    "print(\"videos in google sheet: \", len(id_list))\n",
    "print(\"videos w/ metadata: \", len(ids_with_meta))\n",
    "print(\"videos in google sheet + w/ meta +  detections: \", len(ids_with_dets))\n",
    "print(\"videos in google sheet + w/ meta + detections + segmentation: \", len(ids_with_segs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719402d-2d93-4e27-8a69-75631b20e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = load_json(FRAMES_METADATA_PATH)\n",
    "print(len(fm))\n",
    "\n",
    "fl = pickle.load(open(FRAMES_METADATA_PATH.with_name(\"frames_list.pkl\"), \"rb\"))\n",
    "print(len(fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be24d23-995b-45bb-840f-af9d1d80358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta[df_meta.video_id.isin(ids_list)].split.value_counts()\n",
    "# len(set(df_meta.index.values).intersection(set(id_list)))\n",
    "# df_meta.loc[list(id_list),:]\n",
    "df_meta.index\n",
    "df_meta.loc[[\"K4GXuDACK40\", \"8ytmWvud6-4\"]]\n",
    "df_meta.loc[list(set(df_meta.index.values).intersection(id_list)), :].split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e20b1a-3051-4a88-aeeb-5d534cad19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_with_frames = sorted(Path(\"/shared/gbiamby/geo/video_frames\").glob(\"*/\"))\n",
    "videos_with_frames[:5], len(videos_with_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d44e00-2309-4c09-b40d-2a1c298b45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.head(5)\n",
    "df_frames_meta.shape\n",
    "len(ids_with_segs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390efa86-e7b3-47e6-9acb-65988dc7816d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263e6fb-804d-402b-b7c4-7cad830c86bb",
   "metadata": {},
   "source": [
    "## Process All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d84ec-1935-482e-89be-c888cf0f0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LATEST_DETECTION_MODEL_NAME\n",
    "if \"df_frames_meta\" not in locals():\n",
    "    # One row per video_id, tells you sample rate, num frames sampled, and video fps:\n",
    "    df_frames_meta = pd.read_json(FRAMES_METADATA_PATH, orient=\"index\")\n",
    "\n",
    "if \"df_meta\" not in locals():\n",
    "    # One row per video_id, has the general metadata about the youtube video\n",
    "    df_meta = pd.DataFrame(get_all_geoguessr_split_metadata().values()).set_index(\"id\")\n",
    "\n",
    "if \"frame_paths\" not in locals():\n",
    "    # Dictionary of every single video. key=video_id, val=list of every sampled frame (@4fps)\n",
    "    frame_paths = pickle.load(open(EXTRACTED_FRAMES_PATH / \"frames_list.pkl\", \"rb\"))\n",
    "\n",
    "if \"segs\" not in locals():\n",
    "    # List of video_id's that have segmentations computed\n",
    "    segs = [\n",
    "        str(p.stem.replace(\"df_seg-video_id_\", \"\"))\n",
    "        for p in sorted(Path(\"/shared/gbiamby/geo/segment/seg\").glob(\"**/*.pkl\"))\n",
    "    ]\n",
    "\n",
    "if \"dets\" not in locals():\n",
    "    # List of video_id's that have UI detections computed\n",
    "    dets = [\n",
    "        str(p.stem.replace(\"df_frame_dets-video_id_\", \"\"))\n",
    "        for p in sorted(Path(f\"/shared/gbiamby/geo/segment/detections/{model}\").glob(\"**/*.pkl\"))\n",
    "    ]\n",
    "\n",
    "in_game_frames_all = []\n",
    "video_ids = (\n",
    "    set(df_frames_meta.video_id.values.tolist()).intersection(set(segs)).intersection(set(dets))\n",
    ")\n",
    "print(f\"Total video_ids with segmentations: {len(video_ids):,}\")\n",
    "\n",
    "for i, video_id in tenumerate(video_ids):\n",
    "    # if i > 10:\n",
    "    #     break\n",
    "    frames = subsample_frames(video_id, df_frames_meta, frame_paths)\n",
    "    df_all_frames = pd.DataFrame(frames)\n",
    "    in_game_frames = filter_to_in_game(video_id, frames, df_meta)\n",
    "    in_game_frames_all.extend(in_game_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603cd1e-ebb8-4b1c-a85c-0a241fec5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_game_frames_all[0], f\"{len(in_game_frames_all):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1fa4b-04f8-4e91-a44b-2cfe8596f36e",
   "metadata": {},
   "source": [
    "### Append UI element detections to the frames data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b83778-ed93-43d9-8507-9fd2037faa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dets_all = {}\n",
    "for i, f in tenumerate(in_game_frames_all):\n",
    "    if f[\"video_id\"] not in df_dets_all:\n",
    "        df_dets_all[f[\"video_id\"]] = get_dets(f[\"video_id\"], model, df_meta)\n",
    "    df_dets = df_dets_all[f[\"video_id\"]]\n",
    "    frame_dets = df_dets.loc[f[\"frame_idx\"]]\n",
    "    f[\"time\"] = frame_dets.time\n",
    "    f[\"labels\"] = frame_dets.labels\n",
    "    f[\"scores\"] = frame_dets.scores\n",
    "    f[\"bboxes_640\"] = frame_dets.bboxes\n",
    "    f[\"bboxes\"] = [\n",
    "        transform_box(*b.values(), f[\"img_width\"], f[\"img_height\"]) for b in frame_dets.bboxes\n",
    "    ]\n",
    "    f[\"bboxes\"] = [\n",
    "        {\n",
    "            \"xmin\": b[0][0],\n",
    "            \"ymin\": b[0][1],\n",
    "            \"xmax\": b[0][2],\n",
    "            \"ymax\": b[0][3],\n",
    "            \"area\": b[1],\n",
    "        }\n",
    "        for b in f[\"bboxes\"]\n",
    "    ]\n",
    "    f[\"split\"] = df_meta.loc[f[\"video_id\"]].split\n",
    "    f[\"file_path\"] = str(f[\"file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbb377-c4e6-4892-8a02-cdf716cc5c2c",
   "metadata": {},
   "source": [
    "### Save as both Raw JSON and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3366c0-e63d-4de9-b412-6836bd326961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ingame = (pd.DataFrame(in_game_frames_all).set_index([\"video_id\", \"frame_idx\"], drop=False))[\n",
    "    [\n",
    "        \"video_id\",\n",
    "        \"round_num\",\n",
    "        \"frame_idx\",\n",
    "        \"img_width\",\n",
    "        \"img_height\",\n",
    "        \"sec\",\n",
    "        \"time\",\n",
    "        \"labels\",\n",
    "        \"scores\",\n",
    "        # \"bboxes_640\",\n",
    "        \"bboxes\",\n",
    "        \"split\",\n",
    "        \"file_path\",\n",
    "    ]\n",
    "]\n",
    "df_ingame.index.rename([\"_video_id\", \"_frame_id\"], inplace=True)\n",
    "df_ingame.sort_values([\"video_id\", \"round_num\", \"frame_idx\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94afe32e-55af-47cc-b2b4-3ba75b0ab3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to True to save (ovewrite) the files:\n",
    "if True:\n",
    "    dest_dir = Path(\"/shared/gbiamby/geo/segment\")\n",
    "    assert dest_dir.exists()\n",
    "    assert dest_dir.is_dir()\n",
    "    save_json(dest_dir / \"in_game_frames_000.json\", in_game_frames_all)\n",
    "    pickle.dump(df_ingame, open(dest_dir / \"in_game_frames_000.pkl\", \"wb\"))\n",
    "    pickle.dump(df_ingame, open(dest_dir / \"in_game_frames_000-protocol_3.pkl\", \"wb\"), protocol=3)\n",
    "    pickle.dump(df_ingame, open(dest_dir / \"in_game_frames_000-protocol_4.pkl\", \"wb\"), protocol=4)\n",
    "    pickle.dump(df_ingame, open(dest_dir / \"in_game_frames_000-protocol_5.pkl\", \"wb\"), protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6b30a-1a27-4313-8b2b-883230da44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_ingame)\n",
    "# df_in_game_summary = pd.DataFrame(\n",
    "#     df_ingame.groupby([\"round_num\"]).agg(\n",
    "#         total_frames=(\"frame_idx\", \"count\"),\n",
    "#         start_sec=(\"sec\", \"min\"),\n",
    "#         end_sec=(\"sec\", \"max\"),\n",
    "#         start_frame=(\"frame_idx\", \"min\"),\n",
    "#         end_frame=(\"frame_idx\", \"max\"),\n",
    "#     )\n",
    "# )\n",
    "# display(df_in_game_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799df476-1cdc-42e6-a11b-fff512cb6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ingame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9c730-bed1-461f-b8ca-229033535d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_info_base = load_json(FRAMES_METADATA_PATH)\n",
    "frame_info_new_1 = load_json(FRAMES_METADATA_PATH.with_name(\"frame_meta_003_new_bak.json\"))\n",
    "frame_info_new_2 = load_json(FRAMES_METADATA_PATH.with_name(\"frame_meta_003_new.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83a5e8-f109-4d1f-9540-7ab32b93f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = set(frame_info_base.keys())\n",
    "f1 = set(frame_info_new_1.keys())\n",
    "f2 = set(frame_info_new_2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea211bbe-b2bc-421c-a5c3-9e95c8fa2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(f0), len(f1), len(f2))\n",
    "print(len(f0.intersection(f1)))\n",
    "print(len(f0.intersection(f2)))\n",
    "print(len(f1.intersection(f2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce9064-8647-49d0-a837-3257a386b337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoscreens",
   "language": "python",
   "name": "geoscreens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
