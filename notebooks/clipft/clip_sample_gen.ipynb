{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f70baa-482e-4f31-aa55-2c4c703da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aae395-bd63-4dad-b513-c8538651848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union, cast\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as pil_img\n",
    "from IPython.core.display import HTML, Markdown\n",
    "from IPython.display import Image, display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from PIL import Image as pil_img\n",
    "from tqdm.contrib import tenumerate\n",
    "from tqdm.contrib.bells import tqdm\n",
    "\n",
    "from geoscreens.data import get_all_geoguessr_split_metadata\n",
    "from geoscreens.utils import load_json, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3b28e-5ae7-4225-a1f7-c6e7df6da8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "# Suitable default display for floats\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "\n",
    "# This one is optional -- change graphs to SVG only use if you don't have a\n",
    "# lot of points/lines in your graphs. Can also just use ['retina'] if you\n",
    "# don't want SVG.\n",
    "%config InlineBackend.figure_formats = [\"retina\"]\n",
    "set_matplotlib_formats(\"pdf\", \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947e6af-f2e2-487e-8893-5cc88dd2584f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b37e4-92f5-47fc-9073-643c488e8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import platform\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_ingame = pickle.load(open(\"/shared/gbiamby/geo/segment/in_game_frames_000.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4782f87-823c-4f02-bb87-e89ab0457e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    df_ingame.groupby([\"video_id\", \"img_width\", \"img_height\"]).agg(\n",
    "        total_frames=(\"sec\", \"count\"),\n",
    "        total_rounds=(\"round_num\", \"nunique\"),\n",
    "        # total_frames=(\"sec\", \"count\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f8cb1-e869-44f0-b042-7a5996480ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ingame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915f16-fb5d-4a15-ae84-fcf7e1cb7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True or \"df_meta\" not in locals():\n",
    "    df_meta = pd.DataFrame(\n",
    "        get_all_geoguessr_split_metadata(\n",
    "            force_include=[\"nemo_caption\", \"nemo_caption_entities\"]\n",
    "        ).values()\n",
    "    ).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a27ad-b3ca-4965-a126-1af60472596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta[\"video_id\"] = df_meta.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b348324-a8e4-4078-a224-b73825a5d3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_meta.tail(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d11a7-ebfb-4bdd-ba1f-96c6cf66e2a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b98ac-6441-4657-bbf7-6582ec2f9a0e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Match up the `ec` captions (the ones Grace generated clue similarities for) with Video Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f7591-b604-4adc-ba40-1d22d10d2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "\n",
    "\n",
    "def idx_to_keys(caption_mapping):\n",
    "    start, end = 0, 0\n",
    "    mapping = {}\n",
    "    for k in caption_mapping:\n",
    "        end += len(caption_mapping[k])\n",
    "        mapping[k] = (start, end)\n",
    "        start = end\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def intersect(a, b):\n",
    "    return min(a[1], b[1]) - max(a[0], b[0]) > 0\n",
    "\n",
    "\n",
    "def sentence_to_timings(ann):\n",
    "    caption = \"\".join(ann[\"nemo_caption\"].values())\n",
    "    mapping = idx_to_keys(ann[\"nemo_caption\"])\n",
    "\n",
    "    idx = 0\n",
    "    keys = list(mapping.keys())\n",
    "    sentences = {}\n",
    "    for ent in ann[\"nemo_caption_entities\"]:\n",
    "        if ent[2] == \"sentence\":\n",
    "            timings = [k for k, v in mapping.items() if intersect(ent, v)]\n",
    "            subcaption = caption[ent[0] : ent[1]]\n",
    "            sentences[subcaption] = timings\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def sentence_to_timings_punkt(ann):\n",
    "    caption = \"\".join(ann[\"nemo_caption\"].values()).strip()\n",
    "    mapping = idx_to_keys(ann[\"nemo_caption\"])\n",
    "\n",
    "    sentences = {}\n",
    "    tokenizer = PunktSentenceTokenizer()\n",
    "    subcaptions = list(tokenizer.tokenize(caption))\n",
    "    spans = list(tokenizer.span_tokenize(caption))\n",
    "    for span, subcaption in zip(spans, subcaptions):\n",
    "        timings = [k for k, v in mapping.items() if intersect(span, v)]\n",
    "        sentences[subcaption] = timings\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def get_spans(caption: str, sentences: list[str]):\n",
    "    start = 0\n",
    "    end = len(sentences[0])\n",
    "    spans = []\n",
    "    for i, s in enumerate(sentences):\n",
    "        spans.append((start, end))\n",
    "        start = end\n",
    "        end += len(sentences[i + 1]) if i + 1 < len(sentences) else len(sentences)\n",
    "    return spans\n",
    "\n",
    "\n",
    "def sentence_to_timings_nltk(ann):\n",
    "    caption = \"\".join(ann[\"nemo_caption\"].values()).strip()\n",
    "    time_to_span = idx_to_keys(ann[\"nemo_caption\"])\n",
    "\n",
    "    sentences = OrderedDict()\n",
    "    subcaptions = list(nltk.tokenize.sent_tokenize(caption))\n",
    "    spans = get_spans(caption, subcaptions)\n",
    "    for i, (subcaption, span) in enumerate(zip(subcaptions, spans)):\n",
    "        timings = [time for time, _idx_span in time_to_span.items() if intersect(span, _idx_span)]\n",
    "        sentences[subcaption] = {\n",
    "            \"times\": timings,\n",
    "            \"idx\": i,\n",
    "            \"span\": span,\n",
    "            \"start\": min(timings),\n",
    "            \"end\": max(timings),\n",
    "        }\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def get_meta():\n",
    "    \"\"\"Get metadata for all videos\"\"\"\n",
    "    df_meta = pd.DataFrame(\n",
    "        get_all_geoguessr_split_metadata(\n",
    "            force_include=[\"nemo_caption\", \"nemo_caption_entities\"]\n",
    "        ).values()\n",
    "    ).set_index(\"id\")\n",
    "    df_meta[\"video_id\"] = df_meta.index\n",
    "    return df_meta\n",
    "\n",
    "\n",
    "def load_clue_sims(dataset_type: str):\n",
    "    clue_sims = load_json(\n",
    "        f\"/shared/g-luo/geoguessr/data/data/guidebook/narrations/{dataset_type}.json\"\n",
    "    )\n",
    "    clue_sims = [\n",
    "        # {\"idx\": i, \"clue_sim\": clue_types[0], \"clue_cluster\": clue_types[1], **narration}\n",
    "        # for i, (narration, clue_types) in enumerate(\n",
    "        #     zip(clue_sims[\"narrations\"], clue_sims[\"clue_types\"])\n",
    "        # )\n",
    "        {\"idx\": i, **narration}\n",
    "        for i, (narration) in enumerate(clue_sims[\"narrations\"])\n",
    "    ]\n",
    "    # Update the index for each sentence so it starts at 0 for each video_id:\n",
    "    video_id = clue_sims[0][\"id\"]\n",
    "    idx = 0\n",
    "    for cs in clue_sims:\n",
    "        if cs[\"id\"] != video_id:\n",
    "            idx = 0\n",
    "            video_id = cs[\"id\"]\n",
    "        cs[\"idx\"] = idx\n",
    "        idx += 1\n",
    "\n",
    "    clue_sim_lookup = {(cs[\"id\"], cs[\"text\"], cs[\"idx\"]): cs for cs in clue_sims}\n",
    "    return clue_sims, clue_sim_lookup\n",
    "\n",
    "\n",
    "def get_caption_timings(df_meta: pd.DataFrame):\n",
    "    captions_nltk = {}\n",
    "    for i, video_id in tenumerate(df_meta.video_id.values, desc=\"get_caption_timings\"):\n",
    "        # if i[0] > 0:\n",
    "        #     break\n",
    "        captions_nltk[video_id] = sentence_to_timings_nltk(df_meta.loc[video_id].to_dict())\n",
    "    return captions_nltk\n",
    "\n",
    "\n",
    "def merge_timings_and_clue_sims(\n",
    "    captions_nltk, clue_sims: dict, clue_sim_lookup: list[tuple], clue_sim_ids: set[str]\n",
    "):\n",
    "    num_matches = 0\n",
    "    result = {}\n",
    "    for i, (video_id, sentences) in tenumerate(\n",
    "        captions_nltk.items(), desc=\"merge_timings_and_clue_sims\"\n",
    "    ):\n",
    "        if video_id not in clue_sim_ids:\n",
    "            continue\n",
    "        if video_id not in result:\n",
    "            result[video_id] = []\n",
    "        for sentence, sentence_info in sentences.items():\n",
    "            key = (video_id, sentence, sentence_info[\"idx\"])\n",
    "            if key in clue_sim_lookup:\n",
    "                num_matches += 1\n",
    "                result[video_id].append(\n",
    "                    {\n",
    "                        \"sentence\": sentence,\n",
    "                        \"clue_type\": clue_sim_lookup[key][\"clue_type\"],\n",
    "                        **deepcopy(sentence_info),\n",
    "                    }\n",
    "                )\n",
    "                # sentence_info[\"clue_sim\"] = clue_sim_lookup[key][\"clue_sim\"]\n",
    "                # sentence_info[\"clue_cluster\"] = clue_sim_lookup[key][\"clue_cluster\"]\n",
    "    print(\"num_matches: \", num_matches)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de776148-1b6e-42de-8fca-7e5563052fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs = load_json(f\"/shared/g-luo/geoguessr/data/data/guidebook/narrations/train.json\")[\"narrations\"]\n",
    "# print(type(cs))\n",
    "# list(cs)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a93d0d-b3c8-4b6b-aa73-95bdd38757f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"df_meta_original\" not in locals() or \"captions_nltk_original\" not in locals():\n",
    "    df_meta_original = get_meta()\n",
    "    captions_nltk_original = get_caption_timings(df_meta_original)\n",
    "df_meta = deepcopy(df_meta_original)\n",
    "captions_nltk = deepcopy(captions_nltk_original)\n",
    "print(\"total videos: \", len(captions_nltk))\n",
    "\n",
    "for dataset_type in [\"val\", \"test\", \"train\"]:\n",
    "    print(\"\\n\", \"=\" * 120, f\"\\n{dataset_type}\")\n",
    "    clue_sims, clue_sim_lookup = load_clue_sims(dataset_type)\n",
    "    print(f\"Total clue_sims: {len(clue_sims)}, clue_sims_lookup: {len(clue_sim_lookup)}\")\n",
    "    clue_sim_ids = {c[\"id\"] for c in clue_sims}\n",
    "    print(\n",
    "        f\"Total captions ({dataset_type}): \",\n",
    "        sum([len(t) for video_id, t in captions_nltk.items() if video_id in clue_sim_ids]),\n",
    "    )\n",
    "    result = merge_timings_and_clue_sims(captions_nltk, clue_sims, clue_sim_lookup, clue_sim_ids)\n",
    "    print(\n",
    "        f\"Merged sims + timings -- videos: {len(result)}, sentences: {sum([len(s) for s in result.values()])}\"\n",
    "    )\n",
    "    save_path = Path(f\"/shared/gbiamby/geo/captions/{dataset_type}_captions_with_timings.json\")\n",
    "    save_json(save_path, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570a4a0-a176-4d3e-ae6a-240ba194a364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8021e701-4a8d-4604-a654-5f49113fd50a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d872b89-bf6b-4628-b4c3-052235a3ac8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632abb12-baba-4ee6-8a1a-b5bdba25e196",
   "metadata": {},
   "source": [
    "## Debugging Why Sentence counts aren't matching up with the clue-sim counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac9b07-4527-481e-b762-5c5c8cd0caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"captions_guide\" not in locals() or \"captions_guide_lookup\" not in locals():\n",
    "    guide = load_json(f\"/shared/g-luo/geoguessr/data/data/guidebook/narrations/train.json\")\n",
    "    captions_guide = {}\n",
    "    captions_guide_lookup = {}\n",
    "    for g in tqdm(guide[\"narrations\"]):\n",
    "        if g[\"id\"] not in captions_guide:\n",
    "            captions_guide[g[\"id\"]] = []\n",
    "        captions_guide[g[\"id\"]].append(deepcopy(g))\n",
    "        captions_guide_lookup[(g[\"id\"], g[\"text\"])] = g[\"clue_type\"]\n",
    "# guide_lookup = {n[\"text\"]: n for n in guide[\"narrations\"]}\n",
    "# type(guide[\"narrations\"]), guide[\"narrations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c4144-fce7-4770-87ec-311bc627aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cg video_ids: \", len(captions_guide))\n",
    "print(\"cg[K4GXuDACK40] sentences: \", len(captions_guide[\"K4GXuDACK40\"]))\n",
    "print(\"cg total captions: \", len(captions_guide_lookup))\n",
    "print(captions_guide[\"K4GXuDACK40\"][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157fe8c-1e4a-4b5c-8cbb-96ad2680111c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(captions_old[\"K4GXuDACK40\"]))\n",
    "print(len(captions_new[\"K4GXuDACK40\"]))\n",
    "print(len(captions_nltk[\"K4GXuDACK40\"]))\n",
    "\n",
    "list(captions_old[\"K4GXuDACK40\"].items())[:10]\n",
    "list(captions_nltk[\"K4GXuDACK40\"].items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa260d-74ac-45f7-a85f-873ab4dbe90a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"captions_old\" not in locals():\n",
    "    captions_old = {}\n",
    "    for t, video_id in tqdm(enumerate(df_meta.video_id.values)):\n",
    "        captions_old[video_id] = sentence_to_timings(df_meta.loc[video_id].to_dict())\n",
    "\n",
    "print(len(captions_old))\n",
    "print(\n",
    "    \"total captions \",\n",
    "    sum([len(t) for video_id, t in captions_old.items() if video_id in captions_guide]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3212066-3346-4a44-80aa-8c95001e23f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"captions_new\" not in locals():\n",
    "    captions_new = {}\n",
    "    for video_id in tqdm(df_meta.video_id.values):\n",
    "        captions_new[video_id] = sentence_to_timings_punkt(df_meta.loc[video_id].to_dict())\n",
    "\n",
    "print(len(captions_new))\n",
    "sum([len(t) for video_id, t in captions_new.items() if video_id in captions_guide])\n",
    "# list(captions_new.items())[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e1465-58a7-4928-bb15-72fa507bf1d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9ea05-d95c-44f6-b6ab-2027fec03237",
   "metadata": {},
   "source": [
    "## Simplest Approach: Map ASR Time to Image Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be071e82-6cf9-4732-adf2-a2d0798aba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac7f5f-2923-485a-b213-a663003ab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_ids = {n[\"id\"] for n in narrations[\"narrations\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59170f-9b4b-4496-b86c-cecf2154b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrations = load_json(f\"/shared/g-luo/geoguessr/data/data/guidebook/narrations/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56fe11-2bc2-49b9-a915-c279a7794336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length: \", len(narrations[\"narrations\"]))\n",
    "narrations[\"narrations\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9675e-f1c2-410d-9ab8-3c46e542bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(narrations[\"clue_types\"]))\n",
    "narrations[\"clue_types\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cea744-c7ab-4689-b797-63582e4aeb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52f407a8-52f7-4b24-8c50-22eb41a81c0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828c211-930c-41cc-afbe-b3a1bb7d2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "clues = load_json(\"/shared/g-luo/geoguessr/data/data/guidebook/clues/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0b355-336e-4c2a-9c91-7f0836f99f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clues[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bc6d3-6037-4c22-8676-e5750eac04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885b5e5-4c91-4a7c-ac1c-44794cb5005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b383756-d2bd-481d-acf2-b999d5b78432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = json.load(open(f\"/shared/g-luo/geoguessr/data/data/train.json\"))\n",
    "print(len(dataset))\n",
    "dataset2 = json.load(open(f\"/shared/g-luo/geoguessr/data/data/guidebook/narrations/train.json\"))\n",
    "print(len(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667122f-5b1f-4b77-9239-1ccc3fa2286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrations = [nltk.tokenize.sent_tokenize(\"\".join(ann[\"nemo_caption\"].values())) for ann in dataset]\n",
    "narrations = sum(narrations, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76282bb5-e46b-495c-a9e6-d3a07898d8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(narrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7ea7b-8565-4c38-af93-776f08e6844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "clues = json.load(open(\"/shared/g-luo/geoguessr/data/data/guidebook/text/clues/paragraphs.json\"))\n",
    "cs = [nltk.tokenize.sent_tokenize(c[\"caption\"]) for c in clues.values()]\n",
    "# clue_embeddings = np.vstack([np.mean(model.encode(c), axis=0) for c in cs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a824fbe-2f27-47c0-870b-39872ec9e4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a0d72-d8e3-4e2a-98b1-63874f704f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def get_inv_norm(x):\n",
    "    norm = np.expand_dims(np.linalg.norm(x, axis=1), 1)\n",
    "    return np.where(norm == 0, 0, 1 / norm)\n",
    "\n",
    "\n",
    "def get_labels(clue_embeddings, narration_embeddings):\n",
    "    sims = clue_embeddings @ narration_embeddings.T\n",
    "    values, idxs = torch.max(torch.from_numpy(sims), dim=0)\n",
    "    return [(values[i].item(), idxs[i].item()) for i in range(values.shape[0])]\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset_type = sys.argv[1]\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    dataset = json.load(open(f\"/shared/g-luo/geoguessr/data/data/{dataset_type}.json\"))\n",
    "    narrations = [\n",
    "        nltk.tokenize.sent_tokenize(\"\".join(ann[\"nemo_caption\"].values())) for ann in dataset\n",
    "    ]\n",
    "    narrations = sum(narrations, [])\n",
    "    batch_size = 100\n",
    "\n",
    "    narration_embeddings = []\n",
    "    for i in tqdm(range(0, len(narrations), batch_size)):\n",
    "        with torch.no_grad():\n",
    "            narration_embeddings.extend(model.encode(narrations[i : i + batch_size]))\n",
    "\n",
    "    clues = json.load(\n",
    "        open(\"/shared/g-luo/geoguessr/data/data/guidebook/text/clues/paragraphs.json\")\n",
    "    )\n",
    "    cs = [nltk.tokenize.sent_tokenize(c[\"caption\"]) for c in clues.values()]\n",
    "    clue_embeddings = np.vstack([np.mean(model.encode(c), axis=0) for c in cs])\n",
    "\n",
    "    narration_embeddings = narration_embeddings * get_inv_norm(narration_embeddings)\n",
    "    clue_embeddings = clue_embeddings * get_inv_norm(clue_embeddings)\n",
    "\n",
    "    sims = get_labels(clue_embeddings, narration_embeddings)\n",
    "    # json.dump(\n",
    "    #     sims, open(f\"/shared/g-luo/geoguessr/data/data/guidebook/clues/{dataset_type}.json\", \"w\")\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad565d-0f42-40ae-823e-9dfc99bad535",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = load_json(\"/shared/g-luo/geoguessr/models/clip_zs/placing2014_no_indoor.json\")\n",
    "ref_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa148d-23a5-4265-a75c-b44aa6d6fff2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b10a9b-93e7-4508-bb54-7dea40ba0095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360ccc3-7909-477b-9368-cccea8b612a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoscreens",
   "language": "python",
   "name": "geoscreens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
